{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Step 1: Create a random tensor of shape (4, 6)\n",
        "tensor = tf.random.uniform((4, 6))\n",
        "\n",
        "# Step 2: Find its rank and shape\n",
        "rank = tf.rank(tensor)\n",
        "shape = tf.shape(tensor)\n",
        "\n",
        "print(f\"Original Tensor Rank: {rank.numpy()}\")\n",
        "print(f\"Original Tensor Shape: {shape.numpy()}\")\n",
        "\n",
        "# Step 3: Reshape to (2, 3, 4)\n",
        "reshaped_tensor = tf.reshape(tensor, (2, 3, 4))\n",
        "reshaped_shape = tf.shape(reshaped_tensor)\n",
        "\n",
        "# Transpose to (3, 2, 4)\n",
        "transposed_tensor = tf.transpose(reshaped_tensor, perm=[1, 0, 2])\n",
        "transposed_shape = tf.shape(transposed_tensor)\n",
        "\n",
        "print(f\"Reshaped Tensor Shape: {reshaped_shape.numpy()}\")\n",
        "print(f\"Transposed Tensor Shape: {transposed_shape.numpy()}\")\n",
        "\n",
        "# Step 4: Broadcast a smaller tensor (1, 4) to match the larger tensor and add them\n",
        "small_tensor = tf.random.uniform((4, 1))\n",
        "broadcasted_tensor = tf.broadcast_to(small_tensor, (4, 6))\n",
        "\n",
        "added_tensor = tensor + broadcasted_tensor  # Broadcasting happens automatically\n",
        "\n",
        "print(f\"Broadcasted Tensor Shape: {broadcasted_tensor.shape}\")\n",
        "print(f\"Added Tensor Shape: {added_tensor.shape}\")\n",
        "\n",
        "# Step 5: Explanation of broadcasting\n",
        "\"\"\"\n",
        "Broadcasting in TensorFlow:\n",
        "- Allows tensors of different shapes to be used in element-wise operations.\n",
        "- The smaller tensor (4,1) expands its second dimension to match (4,6).\n",
        "- This process avoids unnecessary memory duplication.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "um8TxC9qCWVy",
        "outputId": "a4847655-73c6-4f21-ae51-a2652b5f9a5b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor Rank: 2\n",
            "Original Tensor Shape: [4 6]\n",
            "Reshaped Tensor Shape: [2 3 4]\n",
            "Transposed Tensor Shape: [3 2 4]\n",
            "Broadcasted Tensor Shape: (4, 6)\n",
            "Added Tensor Shape: (4, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nBroadcasting in TensorFlow:\\n- Allows tensors of different shapes to be used in element-wise operations.\\n- The smaller tensor (4,1) expands its second dimension to match (4,6).\\n- This process avoids unnecessary memory duplication.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}